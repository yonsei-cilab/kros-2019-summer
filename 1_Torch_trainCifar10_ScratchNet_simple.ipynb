{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Torch_trainCifar10_ScratchNet_simple.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"omu4-vsanK3e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"0743594d-347a-409d-ad1e-e3651383bee2"},"source":["from __future__ import print_function\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time\n","\n","\n","\n","class ScratchNet(nn.Module):\n","    def __init__(self):\n","        super(ScratchNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(128 * 4 * 4, 100),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(100, 10),\n","            #nn.Softmax(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","# Define CNN Architecture\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","epochs = 10\n","\n","\n","#Visualizing CIFAR 10\n","trainset = torchvision.datasets.CIFAR10(root='./data',download=True)\n","datanum = len(trainset)\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","fig = plt.figure()\n","ims = np.random.randint(datanum, size=15)\n","\n","for i in range(15):\n","    subplot = fig.add_subplot(3,5, i+1)\n","    subplot.set_xticks([])\n","    subplot.set_yticks([])\n","    PILimg, label = trainset[ims[i]]\n","    subplot.set_title(\"%s\" %classes[label])\n","    subplot.imshow(PILimg)\n","\n","plt.show()\n","\n","\n","\n","# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n","\n","\n","# Model\n","print('==> Building model..')\n","net = ScratchNet()\n","\n","net = net.to(device)\n","if device == 'cuda':\n","    net = torch.nn.DataParallel(net)\n","    cudnn.benchmark = True\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True)\n","\n","\n","\n","# Training\n","def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    print('\\nTrain:')\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    print_time = -1\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        if time.time()-print_time > 1 or print_time == -1 or batch_idx+1 == len(trainloader):\n","            print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)'%(\n","                batch_idx+1, len(trainloader), train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","            \n","            print_time = time.time()\n","\n","\n","def test(epoch):\n","    print('\\nTest:')\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    print_time = -1\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            if time.time()-print_time > 1 or print_time == -1 or batch_idx+1 == len(testloader):\n","                print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)'%(\n","                    batch_idx+1, len(testloader), test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","                \n","                print_time = time.time()\n","                \n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    print('Saving..')\n","    state = {\n","        'net': net.state_dict(),\n","        'acc': acc,\n","        'epoch': epoch,\n","    }\n","    if not os.path.isdir('checkpoint'):\n","        os.mkdir('checkpoint')\n","    torch.save(state, './checkpoint/scratchnet.pt')\n","    best_acc = acc\n","\n","    scheduler.step(test_loss/(batch_idx+1))\n","\n","\n","\n","for epoch in range(epochs):\n","    train(epoch)\n","    test(epoch)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KZ4FmLMHpER2","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time\n","\n","import sklearn.metrics as skl\n","\n","\n","\n","def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    #print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","\n","\n","class ScratchNet(nn.Module):\n","    def __init__(self):\n","        super(ScratchNet, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.2),\n","\n","            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Dropout(p=0.2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(128 * 4 * 4, 100),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(100, 10),\n","            #nn.Softmax(),\n","        )\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","\n","\n","\n","\n","if __name__ == '__main__':\n","    name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","    num_classes = 10\n","\n","\n","    # Load model and weights\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    print('==> Building model..')\n","    net = ScratchNet()\n","    net = net.to(device)\n","    if device == 'cuda':\n","        net = torch.nn.DataParallel(net)\n","        cudnn.benchmark = True\n","\n","    # Load checkpoint.\n","    print('==> Resuming from checkpoint..')\n","    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n","    checkpoint = torch.load('./checkpoint/scratchnet.pt')\n","    net.load_state_dict(checkpoint['net'])\n","    best_acc = checkpoint['acc']\n","    start_epoch = checkpoint['epoch']\n","    net.eval()\n","\n","    # Data\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=len(testset), shuffle=False, num_workers=2)\n","    print(len(testset), 'test samples')\n","\n","    # x_test, y_test = zip(*testset)\n","    # (_, outputdim) = y_test.shape\n","\n","\n","    for batch_idx, (inputs, targets) in enumerate(testloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = net(inputs)\n","        _, predicted = outputs.max(1)\n","\n","\n","    ylabel = targets.cpu().numpy()\n","    yhatlabel = predicted.cpu().numpy()\n","\n","    # Compute confusion matrix\n","    cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n","    np.set_printoptions(precision=2)\n","    is_correct = (ylabel == yhatlabel)\n","    acc = np.sum(is_correct * 1) / len(is_correct)\n","    print('accuracy:%.5f' %acc)\n","\n","\n","    # Plot non-normalized confusion matrix\n","    plt.figure()\n","    plot_confusion_matrix(cnf_matrix, classes=name_list,\n","                      title='Confusion matrix, without normalization')\n","\n","    # Plot normalized confusion matrix\n","    plt.figure()\n","    plot_confusion_matrix(cnf_matrix, classes=name_list, normalize=True,\n","                      title='Normalized confusion matrix')\n","\n","    plt.show()\n","\n","\n"],"execution_count":0,"outputs":[]}]}