{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ScratchNet_trainCifar10_keras.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"5p4-0ijKFgAJ","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.datasets import cifar10\n","from tensorflow.keras import layers\n","from tensorflow.keras import models\n","from tensorflow.keras import optimizers\n","from tensorflow.keras import utils\n","import os\n","\n","\n","#*****************************************************\n","#               Standard\n","#*****************************************************\n","\n","\n","name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","num_classes = 10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = utils.to_categorical(y_train, num_classes)\n","y_test = utils.to_categorical(y_test, num_classes)\n","\n","\n","(datanum, h, w, channum) = x_train.shape\n","(_, outputdim) = y_train.shape\n","\n","\n","\n","#Visualizing CIFAR 10\n","fig = plt.figure()\n","ims = np.random.randint(datanum, size=15)\n","\n","for i in range(15):\n","    subplot = fig.add_subplot(3,5, i+1)\n","    subplot.set_xticks([])\n","    subplot.set_yticks([])\n","    subplot.set_title(\"%s\" %name_list[np.argmax(y_train[ims[i]])])\n","    subplot.imshow(x_train[ims[i],:,:,:])\n","\n","plt.show()\n","\n","\n","# ********************************************************\n","#               Training\n","# ********************************************************\n","\n","# Training Parameters\n","epochs = 10\n","batch_size = 32\n","\n","\n","# *************************************************************\n","#               Model building\n","# *************************************************************\n","\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), padding='same',  activation='relu', input_shape=(h, w, channum)))\n","model.add(layers.BatchNormalization())\n","\n","model.add(layers.Conv2D(32, (3, 3), padding='same',  activation='relu'))\n","model.add(layers.BatchNormalization())\n","\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(64, (3, 3), padding='same',  activation='relu'))\n","model.add(layers.BatchNormalization())\n","\n","model.add(layers.Conv2D(64, (3, 3), padding='same',  activation='relu'))\n","model.add(layers.BatchNormalization())\n","\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Conv2D(128, (3, 3), padding='same',  activation='relu'))\n","model.add(layers.BatchNormalization())\n","\n","model.add(layers.Conv2D(128, (3, 3), padding='same',  activation='relu'))\n","model.add(layers.BatchNormalization())\n","\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Dropout(0.2))\n","\n","model.add(layers.Flatten())\n","model.add(layers.Dense(100, activation='relu'))\n","model.add(layers.Dense(10, activation='softmax'))\n","model.summary()\n","\n","model.compile(optimizer=optimizers.Adam(lr=0.001),\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","\n","history = model.fit(x=x_train, y=y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test),\n","                    verbose=1, shuffle=True)\n","\n","history_dict = history.history\n","history_dict.keys()\n","\n","\n","model_dir = os.path.join(os.getcwd(), 'saved_models')\n","if not os.path.isdir(model_dir):\n","    os.makedirs(model_dir)\n","\n","\n","# Save entire model and weights to the Keras HDF5 format\n","model_name = 'keras_cifar10_trained_model.h5'\n","model_path = os.path.join(model_dir, model_name)\n","model.save(model_path)\n","print('Saved trained model at %s ' % model_path)\n","\n","\n","# *************************************************************\n","#               Visualization\n","# *************************************************************\n","\n","# Training loss\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","epochs = range(1, len(loss) + 1)\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n","\n","\n","\n","# Training accuracy\n","plt.clf()   # 그래프를 초기화합니다\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"t5gx31IIMHvR","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras import utils\n","import sklearn.metrics as skl\n","from tensorflow.keras.datasets import cifar10\n","import os\n","\n","\n","def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    #print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","\n","if __name__ == '__main__':\n","    name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","    num_classes = 10\n","    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","    print('x_train shape:', x_train.shape)\n","    print(x_train.shape[0], 'train samples')\n","    print(x_test.shape[0], 'test samples')\n","    print(x_train.shape[1], 'train samples')\n","    print(x_test.shape[2], 'test samples')\n","\n","    x_train = x_train.astype('float32')\n","    x_test = x_test.astype('float32')\n","    x_train /= 255\n","    x_test /= 255\n","\n","    # Convert class vectors to binary class matrices.\n","    y_train = utils.to_categorical(y_train, num_classes)\n","    y_test = utils.to_categorical(y_test, num_classes)\n","\n","    (_, outputdim) = y_test.shape\n","\n","\n","    # Load model and weights\n","    save_dir = os.path.join(os.getcwd(), 'saved_models')\n","    model_name = 'keras_cifar10_trained_model.h5'\n","    model_path = os.path.join(save_dir, model_name)\n","    model = models.load_model(model_path)\n","    print('Loaded trained model at %s ' % model_path)\n","\n","\n","    #Score trained model.\n","    scores = model.evaluate(x_test, y_test, verbose=2)\n","    print('Test loss:', scores[0])\n","    print('Test accuracy:', scores[1])\n","\n","    target = y_test\n","    pred = model.predict(x_test)\n","\n","\n","    ylabel = np.argmax(target,axis=1)\n","    yhatlabel = np.argmax(pred,axis=1)\n","\n","    # Compute confusion matrix\n","    cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n","    np.set_printoptions(precision=2)\n","    is_correct = (ylabel == yhatlabel)\n","    acc = np.sum(is_correct * 1) / len(is_correct)\n","    print('accuracy:%.5f' %acc)\n","\n","\n","    # Plot non-normalized confusion matrix\n","    plt.figure()\n","    plot_confusion_matrix(cnf_matrix, classes=name_list,\n","                      title='Confusion matrix, without normalization')\n","\n","    # Plot normalized confusion matrix\n","    plt.figure()\n","    plot_confusion_matrix(cnf_matrix, classes=name_list, normalize=True,\n","                      title='Normalized confusion matrix')\n","\n","    plt.show()\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMpNUwG_ZQbh","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras import models\n","from tensorflow.keras import utils\n","import sklearn.metrics as skl\n","from tensorflow.keras.datasets import cifar10\n","import os\n","\n","\n","\n","name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","num_classes = 10\n","(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n","\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices.\n","y_train = utils.to_categorical(y_train, num_classes)\n","y_test = utils.to_categorical(y_test, num_classes)\n","\n","(datanum, h, w, channum) = x_train.shape\n","(_, outputdim) = y_test.shape\n","\n","\n","#Visualizing CIFAR 10\n","fig = plt.figure()\n","ims = np.random.randint(datanum)\n","img_tensor = x_train[ims, :, :, :]\n","plt.title(\"%s\" %name_list[np.argmax(y_train[ims])])\n","plt.imshow(img_tensor)\n","plt.show()\n","img_tensor = np.expand_dims(img_tensor, axis=0)\n","\n","\n","\n","# Load model and weights\n","save_dir = os.path.join(os.getcwd(), 'saved_models')\n","model_name = 'keras_cifar10_trained_model.h5'\n","model_path = os.path.join(save_dir, model_name)\n","model = models.load_model(model_path)\n","print('Loaded trained model at %s ' % model_path)\n","\n","\n","\n","# 상위 8개 층의 출력을 추출합니다:\n","layer_outputs = [layer.output for layer in model.layers[:16]]\n","# 입력에 대해 8개 층의 출력을 반환하는 모델을 만듭니다\n","activation_model = models.Model(inputs=model.input, outputs=layer_outputs)\n","\n","\n","# 층의 활성화마다 하나씩 8개의 넘파이 배열로 이루어진 리스트를 반환합니다:\n","activations = activation_model.predict(img_tensor)\n","\n","\n","\n","## 층의 이름을 그래프 제목으로 사용합니다\n","layer_names = []\n","for layer in model.layers[:16]:\n","    layer_names.append(layer.name)\n","\n","images_per_row = 16\n","\n","# 특성 맵을 그립니다\n","for layer_name, layer_activation in zip(layer_names, activations):\n","    # 특성 맵에 있는 특성의 수\n","    n_features = layer_activation.shape[-1]\n","\n","    # 특성 맵의 크기는 (1, size, size, n_features)입니다\n","    size = layer_activation.shape[1]\n","\n","    # 활성화 채널을 위한 그리드 크기를 구합니다\n","    n_cols = n_features // images_per_row\n","    display_grid = np.zeros((size * n_cols, images_per_row * size))\n","\n","    # 각 활성화를 하나의 큰 그리드에 채웁니다\n","    for col in range(n_cols):\n","        for row in range(images_per_row):\n","            channel_image = layer_activation[0,\n","                                             :, :,\n","                                             col * images_per_row + row]\n","            # 그래프로 나타내기 좋게 특성을 처리합니다\n","            channel_image -= channel_image.mean()\n","            channel_image /= channel_image.std()\n","            channel_image *= 64\n","            channel_image += 128\n","            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n","            display_grid[col * size : (col + 1) * size,\n","                         row * size : (row + 1) * size] = channel_image\n","\n","    # 그리드를 출력합니다\n","    scale = 1. / size\n","    plt.figure(figsize=(scale * display_grid.shape[1],\n","                        scale * display_grid.shape[0]))\n","    plt.title(layer_name)\n","    plt.grid(False)\n","    plt.imshow(display_grid, aspect='auto', cmap='viridis')\n","\n","plt.show()"],"execution_count":0,"outputs":[]}]}