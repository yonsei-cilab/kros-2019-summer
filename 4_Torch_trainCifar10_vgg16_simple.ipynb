{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Torch_trainCifar10_vgg16_simple.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"kQ7dH7NFUDyF","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time\n","\n","\n","\n","\n","cfg = {\n","    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n","    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n","    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n","    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n","}\n","\n","\n","\n","class VGG(nn.Module):\n","    def __init__(self, vgg_name):\n","        super(VGG, self).__init__()\n","        self.features = self._make_layers(cfg[vgg_name])\n","        # self.classifier = nn.Linear(512, 10)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 2 * 2, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 10),\n","        )\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 3\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                           nn.BatchNorm2d(x),\n","                           nn.ReLU(inplace=True)]\n","                in_channels = x\n","        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n","        return nn.Sequential(*layers)\n","\n","\n","\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","epochs = 10\n","\n","\n","#Visualizing CIFAR 10\n","trainset = torchvision.datasets.CIFAR10(root='./data',download=True)\n","datanum = len(trainset)\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","fig = plt.figure()\n","ims = np.random.randint(datanum, size=15)\n","\n","for i in range(15):\n","    subplot = fig.add_subplot(3,5, i+1)\n","    subplot.set_xticks([])\n","    subplot.set_yticks([])\n","    PILimg, label = trainset[ims[i]]\n","    subplot.set_title(\"%s\" %classes[label])\n","    subplot.imshow(PILimg)\n","\n","plt.show()\n","\n","# Data\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","# Model\n","print('==> Building model..')\n","# net = LeNet()\n","# net = ScratchNet()\n","# net = AlexNet()\n","net = VGG('VGG16')\n","# net = VGG('VGG19')\n","# net = ResNet18()\n","# net = ResNet50()\n","# net = SENet18()\n","# net = SENet50()\n","net = net.to(device)\n","if device == 'cuda':\n","    net = torch.nn.DataParallel(net)\n","    cudnn.benchmark = True\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, verbose=True)\n","\n","\n","# Training\n","def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    print('\\nTrain:')\n","    net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    print_time = -1\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        outputs = net(inputs)\n","        loss = criterion(outputs, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets).sum().item()\n","\n","        if time.time() - print_time > 1 or print_time == -1 or batch_idx + 1 == len(trainloader):\n","            print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n","                batch_idx + 1, len(trainloader), train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n","\n","            print_time = time.time()\n","\n","\n","\n","\n","def test(epoch):\n","    print('\\nTest:')\n","    global best_acc\n","    net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    print_time = -1\n","    with torch.no_grad():\n","        for batch_idx, (inputs, targets) in enumerate(testloader):\n","            inputs, targets = inputs.to(device), targets.to(device)\n","            outputs = net(inputs)\n","            loss = criterion(outputs, targets)\n","\n","            test_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += targets.size(0)\n","            correct += predicted.eq(targets).sum().item()\n","\n","            if time.time() - print_time > 1 or print_time == -1 or batch_idx + 1 == len(testloader):\n","                print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)' % (\n","                    batch_idx + 1, len(testloader), test_loss / (batch_idx + 1), 100. * correct / total, correct,\n","                    total))\n","\n","                print_time = time.time()\n","\n","    # Save checkpoint.\n","    acc = 100. * correct / total\n","    print('Saving..')\n","    state = {\n","        'net': net.state_dict(),\n","        'acc': acc,\n","        'epoch': epoch,\n","    }\n","    if not os.path.isdir('checkpoint'):\n","        os.mkdir('checkpoint')\n","    torch.save(state, './checkpoint/ourvgg16.pt')\n","    best_acc = acc\n","\n","    scheduler.step(test_loss / (batch_idx + 1))\n","\n","\n","\n","for epoch in range(epochs):\n","    train(epoch)\n","    test(epoch)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gNAauPjCVfL4","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import time\n","\n","import sklearn.metrics as skl\n","\n","\n","\n","def plot_confusion_matrix(cm, classes,normalize=False,title='Confusion matrix',cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    #print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","\n","cfg = {\n","    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n","    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512],\n","    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512],\n","    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512],\n","}\n","\n","\n","\n","class VGG(nn.Module):\n","    def __init__(self, vgg_name):\n","        super(VGG, self).__init__()\n","        self.features = self._make_layers(cfg[vgg_name])\n","        # self.classifier = nn.Linear(512, 10)\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 2 * 2, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 10),\n","        )\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 3\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                           nn.BatchNorm2d(x),\n","                           nn.ReLU(inplace=True)]\n","                in_channels = x\n","        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n","        return nn.Sequential(*layers)\n","\n","\n","\n","\n","\n","\n","if __name__ == '__main__':\n","    name_list = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","    num_classes = 10\n","\n","\n","    # Load model and weights\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    print('==> Building model..')\n","    net = VGG('VGG16')\n","    net = net.to(device)\n","    if device == 'cuda':\n","        net = torch.nn.DataParallel(net)\n","        cudnn.benchmark = True\n","\n","    # Load checkpoint.\n","    print('==> Resuming from checkpoint..')\n","    assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n","    checkpoint = torch.load('./checkpoint/ourvgg16.pt')\n","    net.load_state_dict(checkpoint['net'])\n","    best_acc = checkpoint['acc']\n","    start_epoch = checkpoint['epoch']\n","    net.eval()\n","\n","    # Data\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","\n","    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","    testloader = torch.utils.data.DataLoader(testset, batch_size=234, shuffle=False, num_workers=2)\n","    print(len(testset), 'test samples')\n","\n","    ylabel = []\n","    yhatlabel = []\n","\n","    for batch_idx, (inputs, targets) in enumerate(testloader):\n","        inputs, targets = inputs.to(device), targets.to(device)\n","        outputs = net(inputs)\n","        _, predicted = outputs.max(1)\n","        ylabel = np.concatenate((ylabel, targets.cpu().numpy()))\n","        yhatlabel = np.concatenate((yhatlabel, predicted.cpu().numpy()))\n","\n","    # Compute confusion matrix\n","    cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n","    np.set_printoptions(precision=2)\n","    is_correct = (ylabel == yhatlabel)\n","    acc = np.sum(is_correct * 1) / len(is_correct)\n","    print('accuracy:%.5f' %acc)\n","\n","\n","    # Plot non-normalized confusion matrix\n","    plt.figure()\n","    plot_confusion_matrix(cnf_matrix, classes=name_list,\n","                      title='Confusion matrix, without normalization')\n","\n","    # Plot normalized confusion matrix\n","    plt.figure()\n","    plot_confusion_matrix(cnf_matrix, classes=name_list, normalize=True,\n","                      title='Normalized confusion matrix')\n","\n","    plt.show()\n"],"execution_count":0,"outputs":[]}]}